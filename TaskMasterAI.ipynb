{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5rbloKsRi/gKmPof7yugc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ja1Pat3L/RadicalX_Challenge2/blob/main/TaskMasterAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dependencies\n",
        "!pip install python-dotenv --quiet\n",
        "!pip install openai --quiet\n",
        "!pip install cohere --quiet\n",
        "!pip install tiktoken --quiet\n",
        "!pip install langchain --quiet\n",
        "!pip install chromadb --quiet\n",
        "!pip install Chroma --quiet\n",
        "!pip install gradio --quiet"
      ],
      "metadata": {
        "id": "f2vXnaLihcHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Packages\n",
        "import os\n",
        "import json\n",
        "import openai\n",
        "from langchain.schema import prompt_template\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain.vectorstores import Chroma\n"
      ],
      "metadata": {
        "id": "CQgYAsfiheax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#API Key\n",
        "OPENAI_API_KEY=\"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\"\n",
        "openai.api_key=OPENAI_API_KEY\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n"
      ],
      "metadata": {
        "id": "bpVYiOurheWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt Template\n",
        "prompt_template = f\"\"\"\n",
        "Context: Generate a coding question with one test Input.\n",
        "Format your response as a JSON object\n",
        "Take out any additional information like examples,outputs,codehints.\n",
        "\"problem_description\" and \"input\" as the keys. Give \"input\" variable a name and store it in a list\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zYjtesM9heUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Response\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt_template,\n",
        "    max_tokens=1024,\n",
        "    n=1,\n",
        "    stop=None,\n",
        "    temperature=0.5,\n",
        ")\n",
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCwDQP3BheRl",
        "outputId": "e13dc7eb-c7e2-4843-c130-123aaa0d8abd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "{\n",
            "    \"problem_description\": \"Write a program to check if a number is divisible by 5 or not\",\n",
            "    \"input\": [\"number\": 5]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "splitter = TokenTextSplitter(chunk_size=100,chunk_overlap=50)\n",
        "\n",
        "texts = splitter.split_text(str(response))\n",
        "\n",
        "print(texts)"
      ],
      "metadata": {
        "id": "TmDqpsnuh0e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f63638-55cf-4574-ca8b-17654fab73fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['{\\n  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\\n  \"id\": \"cmpl-8FnraOdIw0SuIqP71mReEj4scs4aE\",\\n  \"object\": \"text_completion\",\\n  \"created\": 1698777286,\\n ', 'pl-8FnraOdIw0SuIqP71mReEj4scs4aE\",\\n  \"object\": \"text_completion\",\\n  \"created\": 1698777286,\\n  \"model\": \"text-davinci-003\",\\n  \"choices\": [\\n    {\\n      \"text\": \"\\\\n{\\\\n    \\\\\"problem_description\\\\\": \\\\\"Write a program to', ' \"model\": \"text-davinci-003\",\\n  \"choices\": [\\n    {\\n      \"text\": \"\\\\n{\\\\n    \\\\\"problem_description\\\\\": \\\\\"Write a program to check if a number is divisible by 5 or not\\\\\",\\\\n    \\\\\"input\\\\\": [\\\\\"number\\\\\": 5]\\\\n}\",\\n      \"index\": 0,\\n      \"logpro', ' check if a number is divisible by 5 or not\\\\\",\\\\n    \\\\\"input\\\\\": [\\\\\"number\\\\\": 5]\\\\n}\",\\n      \"index\": 0,\\n      \"logprobs\": null,\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 65,\\n  ', 'bs\": null,\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 65,\\n    \"completion_tokens\": 38,\\n    \"total_tokens\": 103\\n  }\\n}', '  \"completion_tokens\": 38,\\n    \"total_tokens\": 103\\n  }\\n}']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Open AI Embeddings\n",
        "embedding_response=OpenAIEmbeddings()\n",
        "embedded_chunks=embedding_response.embed_documents(texts)"
      ],
      "metadata": {
        "id": "y1e4DzKSh2TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ChromaClient"
      ],
      "metadata": {
        "id": "woXaRF7D911G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from chromadb import Chroma\n",
        "from chromadb import ChromaClient\n",
        "\n",
        "client = ChromaClient()\n",
        "db = client.database(\"my_db\")\n",
        "collection = db.collection(\"my_collection\")\n",
        "\n",
        "collection.add(texts, embedded_chunks)\n",
        "\n",
        "#Similarity Search API\n",
        "result=db.similarity_search(\"\")\n",
        "\n",
        "#Printing Result\n",
        "print(result[0].text)"
      ],
      "metadata": {
        "id": "i-mWvYeWh388"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}